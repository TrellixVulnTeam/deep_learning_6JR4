# 深度学习基础知识

[**1. 数据预处理**](#数据预处理)

[**2. 权重初始化**](#权重初始化)

[**3. 正则化**](#正则化)

[**4. 集成**](#集成)

[**5. Dropout**](#dropout)

[**深度学习面试准备网址**](#深度学习面试准备网址)


---

##  数据预处理

（1）**减均值**<br>
（2）**大小缩放**，统一在\[-1,1]或者\[0,1]区间内的数据更利于模型的处理<br>
（3）**标准化**，z-score

## 权重初始化

（1）**全零初始化**，不适合深度学习，会打破神经元之间的对称性，将导致收敛速度很慢甚至训练失败<br>
（2）**随机初始化**，不适合深度学习，比较难把握权重的大小与相关神经元数量的关系，则对应的输出值方差会出现较大的差异，导致收敛速度很慢甚至失败<br>
（3）**方差校准**，避免了随机初始化方差不稳定的问题<br>
（4）**Batch Normalization**，批量规范化的出现在一定程度上缓解了初始化问题

## 正则化

（1）**提前终止**，当验证集上的误差不在减小甚至增大时停止训练<br>
（2）**数据增强**，可以通过噪声、裁剪等方法获取更多数据<br>
（3）**L2/L1参数正则化**，损失函数加正则项；正则原理：L2/L1是添加一个参数w取0附近的先验；具体看书98页<br>

## 集成
    
（1）**生成多个模型的方法有多种**
  
  - 对数据进行放回重采样Bagging(Boostrap Aggregating)--从数量为n的原始数据D中分别独立随机抽取n次，由于是放回重采样，
  每次抽取的候选集都是同样的n个数据，这样得到的新数据集用于训练模型。重复这个过程，就会得到多个模型。<br>
  - Boosting--先针对原始数据训练一个比随机分类器性能要好一点的模型，然后用改分类器对训练数据进行预测，<br>
  对预测错误的数据进行加权，从而组成一个新的训练集，重新训练即可得到新的模型<br>
  - 不同的训练数据--比如要对视频进行分类，部分模型用语音数据，部分模型用字幕图像数据<br>
  - 不同的模型结构--比如有的卷积模型用三层卷积，有的用五层卷积，同样的训练数据也可以出来不同的模型
  
（2）**合并多个模型的方法也有多种**

  - 选择验证集上效果最好的模型<br>
  - 对多个模型进行投票或取平均值<br>
  - 对多个模型的预测结果进行加权平均
  
## Dropout

（1）Dropout是深度学习领域比较常见的正则化方法<br>
（2）训练时dropout，验证或测试时不要dropout

##


---

参考网址：

[DeepLearningBookQA_cn]
(https://github.com/elviswf/DeepLearningBookQA_cn) or (https://nbviewer.jupyter.org/github/laobadao/Deep-Learning-Interview/blob/master/Deep%20Learning%20Interview.ipynb)