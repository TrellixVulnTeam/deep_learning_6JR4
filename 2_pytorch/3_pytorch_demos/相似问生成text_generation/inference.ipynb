{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T01:09:26.277879Z",
     "start_time": "2022-05-22T01:08:47.055516Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RoFormerTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Some weights of RoFormerForCausalLM were not initialized from the model checkpoint at pretrain/roformer_chinese_sim_char_base and are newly initialized: ['roformer.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/zhoubin/anaconda3/envs/pl_torch/lib/python3.8/site-packages/transformers/modeling_utils.py:656: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['广州和深圳哪个好！', '广州和深圳，哪个好？', '广州和深圳哪个好', '广州和深圳哪个好呢？', '广州和深圳，哪个好', '广州和深圳那个好', '广州跟深圳哪个好？', '广州和深圳哪个更好？', '广州与深圳哪个好？', '广州和深圳哪个比较好？', '广州和深圳哪个更好', '广州与深圳哪个好', '广州和深圳哪个比较好', '广州与深圳哪个好一些', '深圳和广州哪个好？', '深圳和广州哪个好呢？', '深圳和广州哪个好', '深圳和广州哪个好啊', '深圳和广州那个好？', '深圳和广州那个好']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from roformer import RoFormerForCausalLM, RoFormerConfig\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "pretrained_model = \"pretrain/roformer_chinese_sim_char_base\"\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "config = RoFormerConfig.from_pretrained(pretrained_model)\n",
    "config.is_decoder = True\n",
    "config.eos_token_id = tokenizer.sep_token_id\n",
    "config.pooler_activation = \"linear\"\n",
    "model = RoFormerForCausalLM.from_pretrained(pretrained_model, config=config)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def gen_synonyms(text, n=100, k=20):\n",
    "    ''''含义： 产生sent的n个相似句，然后返回最相似的k个。\n",
    "    做法：用seq2seq生成，并用encoder算相似度并排序。\n",
    "    '''\n",
    "    # 寻找所有相似的句子\n",
    "    r = []\n",
    "    inputs1 = tokenizer(text, return_tensors=\"pt\")\n",
    "    for _ in range(n):\n",
    "        inputs1.to(device)\n",
    "        output = tokenizer.batch_decode(model.generate(**inputs1, top_p=0.95, do_sample=True, max_length=128), skip_special_tokens=True)[0].replace(\" \",\"\").replace(text, \"\") # 去除空格，去除原始text文本。\n",
    "        r.append(output)\n",
    "    \n",
    "    # 对相似的句子进行排序\n",
    "    r = [i for i in set(r) if i != text and len(i) > 0]\n",
    "    r = [text] + r\n",
    "    inputs2 = tokenizer(r, padding=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        inputs2.to(device)\n",
    "        outputs = model(**inputs2)\n",
    "        Z = outputs.pooler_output.cpu().numpy()\n",
    "    Z /= (Z**2).sum(axis=1, keepdims=True)**0.5\n",
    "    argsort = np.dot(Z[1:], -Z[0]).argsort()\n",
    "    \n",
    "    return [r[i + 1] for i in argsort[:k]]\n",
    "\n",
    "out = gen_synonyms(\"广州和深圳哪个好？\")\n",
    "print(out)\n",
    "# ['深圳和广州哪个好？',\n",
    "#  '广州和深圳哪个好',\n",
    "#  '深圳和广州哪个好',\n",
    "#  '深圳和广州哪个比较好。',\n",
    "#  '深圳和广州哪个最好？',\n",
    "#  '深圳和广州哪个比较好',\n",
    "#  '广州和深圳那个比较好',\n",
    "#  '深圳和广州哪个更好？',\n",
    "#  '深圳与广州哪个好',\n",
    "#  '深圳和广州，哪个比较好',\n",
    "#  '广州与深圳比较哪个好',\n",
    "#  '深圳和广州哪里比较好',\n",
    "#  '深圳还是广州比较好？',\n",
    "#  '广州和深圳哪个地方好一些？',\n",
    "#  '广州好还是深圳好？',\n",
    "#  '广州好还是深圳好呢？',\n",
    "#  '广州与深圳哪个地方好点？',\n",
    "#  '深圳好还是广州好',\n",
    "#  '广州好还是深圳好',\n",
    "#  '广州和深圳哪个城市好？']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
